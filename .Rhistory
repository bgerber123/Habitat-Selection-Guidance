# Create spatial covariate variables
# dist.dev = Euclidean distance to nearest development
# forest = percent forest cover at a relevant spatial scale
# shrub = shrub cover at a relevant spatial scale
# These are continuous variables that are scaled to a mean of 0 and stdev of 1
set.seed(51234)
x = data.frame(dist.dev=rnorm(n),forest=runif(n),shrub=runif(n))
# Create one dataset per each individual with equal
# Note that in the simulation function (simulateUsedAvail) we are specif icing
# a link of 'log' indicating we will be fitting a model to estimate
#  RELATIVE habitat selection rather than absolute selection.
sims = apply(betas,1,FUN=function(b){
ResourceSelection::simulateUsedAvail(data=x,
parms=b,
n.used=n.used,
m=m,
link="log"
)
})
# Check the dimensions of the data
# This should have the same length as n.indiv
length(sims)
# Look at one individual's dataset
dim(sims[[1]])
head(sims[[1]])
table(sims[[1]]$status)
# Combine data into a single data.frame
sims2 = do.call("rbind", sims)
head(sims2)
dim(sims2)
#Create ID vector for individual's data
ID = rep(1:n.indiv, each = nrow(sims[[1]]))
sims2$ID = ID
head(sims2)
dim(sims2)
# Create a vector to weight the 0's by 1000 and the 1's by 1
# This is discussed below  (see manuscript section 10. The model being approximated)
sims2$weight = 1000^(1-sims2$status)
#We will use data from individual #20
indiv.data20 = sims[[20]]
# Let's look at the data to remind us what it is
head(indiv.data20)
# We are now ready to approximate our true model using the generaled linear modeling
# machinery of logistic regression. We will do this using two different packages and functions.
# Here we are using the glmmTMB function in package glmmTMB
# We have related our response variable of the used and available sample (status)
# to our covariates. This is an additive model, as opposed to having interactions.
model1 = glmmTMB::glmmTMB(status ~ dist.dev+forest+shrub,
family=binomial(),
data = indiv.data20
)
# Look at estimated coeficients
summary(model1)
n.available = seq(10,length(index.0),by=100)
indiv.dat1 = sims[[1]]
# index the used (1) and available (0) data
index.0 = which(indiv.dat1==0)
index.1 = which(indiv.dat1==1)
# Create a sequence of the number of available locations to consider
n.available = seq(10,length(index.0),by=100)
n.available
# Size of available samples per used locaiton
n.avail2=c(10,50,100,1000,2000,4000)
#Save coefficients
coef.save=NULL
i=1
sample(indiv.dat1[index.0],n.available[i])
# index the used (1) and available (0) data
index.0 = which(indiv.dat1==0)
indiv.dat1[index.0]
indiv.dat1
indiv.dat1
indiv.dat1[index.0]
index.0
sample(index.0,n.available[i])
dat.temp = rbind(indiv.dat1[index.1,],
indiv.dat1[sample(index.0,n.available[i]),]
)
# fit model with data
model.temp = clogit(status ~ dist.dev + forest + shrub + strata(strata),
data = ind.dat
)
coef.save= rbind(coef.save,
coef(model.temp)
)
#Loop across available sample sizes
for(i in 1:length(n.avail2)){
#re-sample each available sample size 20 times
for (z in 1:20){
#Loop through each used location and reduce the number of available samples
ind.dat=NULL
for(j in 1:length(n.available)){
dat.temp = rbind(indiv.dat1[index.1,],
indiv.dat1[sample(index.0,n.available[i]),]
)
# fit model with data
model.temp = clogit(status ~ dist.dev + forest + shrub + strata(strata),
data = ind.dat
)
coef.save= rbind(coef.save,
coef(model.temp)
)
}#end j loop
}#end z sample loop
}#end i loop
# Size of available samples per used locaiton
n.avail2=c(10,50,100,1000,2000,4000)
#Save coefficients
coef.save=NULL
#Loop across available sample sizes
for(i in 1:length(n.avail2)){
#re-sample each available sample size 20 times
for (z in 1:20){
#Loop through each used location and reduce the number of available samples
ind.dat=NULL
for(j in 1:length(n.available)){
dat.temp = rbind(indiv.dat1[index.1,],
indiv.dat1[sample(index.0,n.avail2[i]),]
)
# fit model with data
model.temp = clogit(status ~ dist.dev + forest + shrub + strata(strata),
data = ind.dat
)
coef.save= rbind(coef.save,
coef(model.temp)
)
}#end j loop
}#end z sample loop
}#end i loop
# Size of available samples per used locaiton
n.avail2=c(10,50,100,1000,2000,4000)
i=1
z=1
j=1
#Loop through each used location and reduce the number of available samples
ind.dat=NULL
for(j in 1:length(n.available)){
dat.temp = rbind(indiv.dat1[index.1,],
indiv.dat1[sample(index.0,n.avail2[i]),]
)
# fit model with data
model.temp = clogit(status ~ dist.dev + forest + shrub + strata(strata),
data = ind.dat
)
coef.save= rbind(coef.save,
coef(model.temp)
)
}#end j loop
#Loop through each used location and reduce the number of available samples
ind.dat=NULL
dat.temp = rbind(indiv.dat1[index.1,],
indiv.dat1[sample(index.0,n.avail2[i]),]
)
# fit model with data
model.temp = clogit(status ~ dist.dev + forest + shrub + strata(strata),
data = ind.dat
)
ind.dat
# fit model with data
model.temp = clogit(status ~ dist.dev + forest + shrub + strata(strata),
data = dat.temp
)
coef.save= rbind(coef.save,
coef(model.temp)
)
head(dat.temp)
dat.temp = rbind(indiv.dat1[index.1,],
indiv.dat1[sample(index.0,n.avail2[i]),]
)
#Create the weighting vector (a 1 for each 1 and a 1000 for each 0)
dat.temp$weight = 1000^(1-dat.temp$status)
model.fit <-  glmmTMB(status ~ dist.dev+forest+shrub,
family = binomial(),
data =  dat.temp,
weight = weight # add the weighting vector
)
coef(model.temp)
coef.save= rbind(coef.save,
coef(model.temp)
)
# Grab individual one's data
indiv.dat1 = sims[[1]]
# index the used (1) and available (0) data
index.0 = which(indiv.dat1==0)
index.1 = which(indiv.dat1==1)
# Create a sequence of the number of available locations to consider
n.available = seq(10,length(index.0),by=100)
# Create storage objects
coef.save = NULL
# Loop through and modify the data and fit each model with increasing
# number of available samples
for(i in 1:length(n.available)){
dat.temp = rbind(indiv.dat1[index.1,],
indiv.dat1[index.0[1:n.available[i]],]
)
#Create the weighting vector (a 1 for each 1 and a 1000 for each 0)
dat.temp$weight = 1000^(1-dat.temp$status)
model.fit =  glmmTMB(status ~ dist.dev+forest+shrub,
family = binomial(),
data =  dat.temp,
weight = weight # add the weighting vector
)
coef.save = rbind(coef.save,
fixef(model.fit)[[1]]
)
}
coef.save
dim(coef.save)
head(coef.save)
# Size of available samples per used locaiton
n.avail2=c(10,50,100,1000,2000,4000)
#Save coefficients
coef.save=NULL
#Loop across available sample sizes
for(i in 1:length(n.avail2)){
#re-sample each available sample size 20 times
for (z in 1:20){
#Loop through each used location and reduce the number of available samples
ind.dat=NULL
dat.temp = rbind(indiv.dat1[index.1,],
indiv.dat1[sample(index.0,n.avail2[i]),]
)
#Create the weighting vector (a 1 for each 1 and a 1000 for each 0)
dat.temp$weight = 1000^(1-dat.temp$status)
model.fit =  glmmTMB(status ~ dist.dev+forest+shrub,
family = binomial(),
data =  dat.temp,
weight = weight # add the weighting vector
)
coef.save= rbind(coef.save,
coef(model.temp)
)
}#end z sample loop
}#end i loop
one = data.frame(N.Avail=rep(n.avail2,each=n.sample),
Sample=rep(1:n.sample,length(n.avail2)),
beta = coef.save[,1]
)
n.sample
n.sample=20
one = data.frame(N.Avail=rep(n.avail2,each=n.sample),
Sample=rep(1:n.sample,length(n.avail2)),
beta = coef.save[,1]
)
two = data.frame(N.Avail=rep(n.avail2,each=n.sample),
Sample=rep(1:n.sample,length(n.avail2)),
beta = coef.save[,2]
)
three = data.frame(N.Avail=rep(n.avail2,each=n.sample),
Sample=rep(1:n.sample,length(n.avail2)),
beta = coef.save[,3]
)
plot.data = rbind(one,two,three)
one = data.frame(N.Avail=rep(n.avail2,each=n.sample),
Sample=rep(1:n.sample,length(n.avail2)),
beta = coef.save[,1]
)
two = data.frame(N.Avail=rep(n.avail2,each=n.sample),
Sample=rep(1:n.sample,length(n.avail2)),
beta = coef.save[,2]
)
three = data.frame(N.Avail=rep(n.avail2,each=n.sample),
Sample=rep(1:n.sample,length(n.avail2)),
beta = coef.save[,3]
)
one = data.frame(N.Avail=rep(n.avail2,each=n.sample),
Sample=rep(1:n.sample,length(n.avail2)),
beta = coef.save[,1]
)
two = data.frame(N.Avail=rep(n.avail2,each=n.sample),
Sample=rep(1:n.sample,length(n.avail2)),
beta = coef.save[,2]
)
three = data.frame(N.Avail=rep(n.avail2,each=n.sample),
Sample=rep(1:n.sample,length(n.avail2)),
beta = coef.save[,3]
)
four = data.frame(N.Avail=rep(n.avail2,each=n.sample),
Sample=rep(1:n.sample,length(n.avail2)),
beta = coef.save[,4]
)
plot.data = rbind(one,two,three,four)
coef.save[,4]
dim(coef.save)
coef(model.temp)
coef(model.fit)
model.fit
coef(model.fit)
model.fit$fit$par
# Size of available samples per used locaiton
n.avail2=c(10,50,100,1000,2000,4000)
# Nunber of sample replications
n.sample = 20
#Save coefficients
coef.save=NULL
#Loop across available sample sizes
for(i in 1:length(n.avail2)){
#re-sample each available sample size 20 times
for (z in 1:n.sample){
#Loop through each used location and reduce the number of available samples
ind.dat=NULL
dat.temp = rbind(indiv.dat1[index.1,],
indiv.dat1[sample(index.0,n.avail2[i]),]
)
#Create the weighting vector (a 1 for each 1 and a 1000 for each 0)
dat.temp$weight = 1000^(1-dat.temp$status)
model.fit =  glmmTMB(status ~ dist.dev+forest+shrub,
family = binomial(),
data =  dat.temp,
weight = weight # add the weighting vector
)
coef.save= rbind(coef.save,
model.fit$fit$par
)
}#end z sample loop
}#end i loop
one = data.frame(N.Avail=rep(n.avail2,each=n.sample),
Sample=rep(1:n.sample,length(n.avail2)),
beta = coef.save[,1]
)
two = data.frame(N.Avail=rep(n.avail2,each=n.sample),
Sample=rep(1:n.sample,length(n.avail2)),
beta = coef.save[,2]
)
three = data.frame(N.Avail=rep(n.avail2,each=n.sample),
Sample=rep(1:n.sample,length(n.avail2)),
beta = coef.save[,3]
)
four = data.frame(N.Avail=rep(n.avail2,each=n.sample),
Sample=rep(1:n.sample,length(n.avail2)),
beta = coef.save[,4]
)
plot.data = rbind(one,two,three,four)
plot.data$Name = c(rep("Intercept",nrow(one)),
rep("dist.dev",nrow(one)),
rep("forest",nrow(one)),
rep("shrub",nrow(one))
)
plot.data$N.Avail = as.factor(plot.data$N.Avail)
colnames(plot.data) = c("N.Available.Sample","Sample","Coeficient.Estiamte","Name")
ggplot2::ggplot(plot.data, aes(N.Available.Sample, Coeficient.Estiamte, fill=factor(Name))) +
theme_bw()+
geom_boxplot()
version$version.string
citatoin
citation
citation()
setwd("~/GitHub/habitat-selection-guidance")
rmarkdown::render("MovementHSF.Rmd", md_document(variant = "markdown_github"))
?rmarkdown::render
?md_document
rmarkdown::render("MovementHSF.Rmd", md_document(variant = "md_document"))
library(rmarkdown)
rmarkdown::render("MovementHSF.Rmd", md_document(variant = "markdown_github"))
rmarkdown::render("TraditionalHSF.Rmd", md_document(variant = "markdown_github"))
grateful::cite_packages
?grateful::cite_packages
# Load spatial covariates stored in a save R object
load("Covs")
setwd("~/GitHub/habitat-selection-guidance")
# Load spatial covariates stored in a save R object
load("Covs")
hsf.true.behav=vector("list",2)
hsf.true.behav[[1]]=covs[[2]]*2
hsf.true.behav[[2]]=covs[[2]]*-2
sim.behav1 =  sim.ind.movement.hsf(hsf.true = hsf.true.behav,
n.time = n.time,
n.step = n.step,
n.avail = n.avail,
angle.mean = angle.mean,
angle.kappa = angle.kappa,
step.rate = step.rate
)
#Load packages
library(geoR)
library(circular)
library(glmmTMB)
library(raster)
library(sp)
library(survival)
library(Rfast)
library(remotes)
library(plotrix)
library(ggplot2)
library(knitr)
# Install github repository
#    remotes::install_github("Pakillo/grateful")
library(grateful)
# Source simulation function
source("sim.ind.movement.hsf.r")
# Source bootstrapping function
source("mean_ci_boot.r")
# Load spatial covariates stored in a save R object
load("Covs")
# Number of Sampled individuals (e.g., tracked via GPS telemetry)
n.indiv = 20
# Define the true population-level coefficients
# and use these to simulate individual-level coefficients
# Selection against at population-level
# Low variation among individuals
beta1.mu = -1
beta1.sd = 0.2
set.seed(543543)
beta1=rnorm(n.indiv,
mean = beta1.mu,
sd = beta1.sd
)
# No selection at population-level
# Wide variation among individuals
beta2.mu = 0
beta2.sd = 1
set.seed(5435431)
beta2=rnorm(n.indiv,
mean = beta2.mu,
sd = beta2.sd
)
# Selection for this feature at population-level
# Low variation among individuals
beta3.mu = 1
beta3.sd = 0.2
set.seed(1543543)
beta3=rnorm(n.indiv,
mean = beta3.mu,
sd = beta3.sd
)
# Combine coefficients and plot these values
betas=data.frame(b1 = beta1,
b2 = beta2,
b3 = beta3)
# Combine into 1 raster stack
covs=stack(covs[[1]], covs[[2]],covs[[3]])
# Change the extent to be larger to accommodate more realistic movements
#  (not required but makes me feel better)
extent(covs)=c(0,1000,0,1000)
# Names of variables
names(covs[[1]]) = 'dist.dev'
names(covs[[2]]) = 'forest'
names(covs[[3]]) = 'shrub'
par(mfrow=c(2,3))
plot(covs[[1]], main='dist.dev')
plot(covs[[2]], main='forest')
plot(covs[[3]], main='shrub')
hist(values(covs[[1]]), main='dist.dev')
hist(values(covs[[2]]), main='forest')
hist(values(covs[[3]]), main='shrub')
hsf.true.behav=vector("list",2)
hsf.true.behav[[1]]=covs[[2]]*2
hsf.true.behav[[2]]=covs[[2]]*-2
sim.behav1 =  sim.ind.movement.hsf(hsf.true = hsf.true.behav,
n.time = n.time,
n.step = n.step,
n.avail = n.avail,
angle.mean = angle.mean,
angle.kappa = angle.kappa,
step.rate = step.rate
)
# Set number of available samples per used
n.avail = 100
# Number of movements
n.time = 400
# Number of possible steps to choose from at each iteration- these are not available locations, this is for the simulation of the movement path
n.step = 400
# Population (across individual) turning angle parameters for von mises distribution
angle.mean = 0
angle.kappa = 0.00001
# Step length rate of exponential distribution
step.rate = 0.2
# Simulate individual-level movement-based habitat selection data
sims =  sim.ind.movement.hsf(hsf.true=hsf.true,
n.time=n.time,
n.step=n.step,
n.avail=n.avail,
angle.mean=angle.mean,
angle.kappa=angle.kappa,
step.rate=step.rate
)
hsf.true.behav=vector("list",2)
hsf.true.behav[[1]]=covs[[2]]*2
hsf.true.behav[[2]]=covs[[2]]*-2
sim.behav1 =  sim.ind.movement.hsf(hsf.true = hsf.true.behav,
n.time = n.time,
n.step = n.step,
n.avail = n.avail,
angle.mean = angle.mean,
angle.kappa = angle.kappa,
step.rate = step.rate
)
# Combine the data
data.ignore= rbind(sim.behav1$indiv[[1]],
sim.behav1$indiv[[2]]
)
#Create ID vector for the different behavioral data
ID=rep(1:2,each=nrow(sim.behav1$indiv[[1]]))
data.ignore$ID=ID
#Create ID vector for unique strata within individual
data.ignore$indiv.id.strata=unique(data.ignore$ID+data.ignore$strata*100)
model.ignore.behav =  clogit(status ~ dist.dev + strata(indiv.id.strata),
data = data.ignore
)
summary(model.ignore.behav)
hsf.true.behav = vector("list",2)
hsf.true.behav[[1]]=covs[[2]]*2
hsf.true.behav[[2]]=covs[[2]]*-2
sim.behav1 =  sim.ind.movement.hsf(hsf.true = hsf.true.behav,
n.time = n.time,
n.step = n.step,
n.avail = n.avail,
angle.mean = angle.mean,
angle.kappa = angle.kappa,
step.rate = step.rate
)
n.avail
