---
title: "Traditional Habitat Selection <br> Guidance (in practice)"
author: "Brian D. Gerber"
date: "2024-12-13"
output: 
  github_document:
    html_preview: FALSE  
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    code_folding: show
    keep_md: true
knit: (function(inputFile, encoding) {
  rmarkdown::render(inputFile, encoding = encoding,
  output_format = "all") })
---

<style type="text/css">
body, td {
   font-size: 14px;
}
code.r{
  font-size: 16px;
}
pre {
  font-size: 16px
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

This vignette is associated with the manuscript titled, 'A plain language review and guidance for modeling animal habitat-selection'. We will be demonstrating some of the points made in the manuscript on fitting models to estimate traditional habitat selection functions (HSF) at the third-order of selection (e.g. selection within the home range). 

*Note:* some of the code-chunks are not automatically displayed. To show the code, select 'show'. 

## Setup

### Environment

```{r packages, results='hide',message=FALSE, class.source = "fold-hide"}
#Load packages
  library(ResourceSelection)
  library(glmmTMB)
  library(plotrix)
  library(broom.mixed)
  library(knitr)
  library(amt)
  library(remotes)
  library(ggplot2)

# A github repository to install
#  remotes::install_github("Pakillo/grateful")
  library(grateful)

# Source bootstrapping function
  source("mean_ci_boot.r")
```

### Simulate data

We will consider a habitat selection analysis of individuals within a broad geographic area (e.g., home range; third-order of selection). Within each individual's home range the effects on habitat selection are assumed to come from a distribution of effects that can be characterized by a mean and standard deviation (i.e., random effect). 

```{r setup.parameters, class.source = "fold-hide"}
# Number of Sampled individuals (e.g., tracked via GPS telemetry)
  n.indiv = 20

# Define the true population-level coefficients
# and use these to simulate individual-level coefficients

  #Intercept - Make them all the same, except the last individual
  # This difference is used below.
    beta0 = c(rep(1.5,(n.indiv-1)),0.2)
    
  # Selection against at population-level 
  # Low variation among individuals 
    beta1.mu = -1
    beta1.sd = 0.2
    
    set.seed(543543)
    beta1 = rnorm(n.indiv, 
                  mean = beta1.mu,
                  sd = beta1.sd
                  )
  # No selection at population-level
  # Wide variation among individuals  
    beta2.mu = 0
    beta2.sd = 1
    
    set.seed(5435431)
    beta2 = rnorm(n.indiv, 
                  mean = beta2.mu,
                  sd = beta2.sd
                  )
  
  # Selection for this feature at population-level 
  # Low variation among individuals
    beta3.mu = 1
    beta3.sd = 0.2
    
    set.seed(1543543)
    beta3 = rnorm(n.indiv, 
                  mean = beta3.mu,
                  sd = beta3.sd
                  )

# Combine coefficients and plot these values
  betas = data.frame(b0 = beta0, 
                     b1 = beta1,
                     b2 = beta2,
                     b3 = beta3
                     )
```

```{r visualize true coeficients, fig.height=8,fig.width=6, class.source = "fold-hide"}
  par(mfrow=c(3,1))
  hist(betas[,2],xlab=bquote(beta[1]),xlim=c(-3,3),main="True Individual Coeficient Values",breaks=10,freq=FALSE)
  abline(v=beta1.mu,lwd=2,col=2)
  curve(dnorm(x,beta1.mu,beta1.sd),lwd=3,col=3,add=TRUE)
  legend("topright",lwd=3,col=c("gray","red","green"),legend=c("Indiv. Coefs", "Pop. Mean","True Distribution"))
  
  hist(betas[,3],xlab=bquote(beta[2]),xlim=c(-3,3),main="",breaks=20,freq=FALSE)
  abline(v=beta2.mu,lwd=2,col=2)
  curve(dnorm(x,beta2.mu,beta2.sd),lwd=3,col=3,add=TRUE)
  legend("topright",lwd=3,col=c("gray","red","green"),legend=c("Indiv. Coefs", "Pop. Mean","True Distribution"))

  hist(betas[,4],xlab=bquote(beta[3]),xlim=c(-3,3),main="",breaks=20,freq=FALSE)
  abline(v=beta3.mu,lwd=2,col=2)
  curve(dnorm(x,beta3.mu,beta3.sd),lwd=3,col=3,add=TRUE)
  legend("topright",lwd=3,col=c("gray","red","green"),legend=c("Indiv. Coefs", "Pop. Mean","True Distribution"))

```

We are now ready to simulate individual-level data. We will do this with the  `simulateUsedAvail` function from the R package `ResourceSelection`. Because of this, we are not simulating spatial (x-y) data from explicit spatial layers, but we will connect how these data represent typical GPS data and setup when working with spatial variables. 

```{r simualte.data, cache=TRUE, class.source = "fold-hide"}
# How many used samples per individual   
  n.used = 500

# Ratio of used:available
  m = 10 
  
#Create available samples  
  n=n.used*m 

# Create spatial covariate variables
# dist.dev = Euclidean distance to nearest development
# forest = percent forest cover at a relevant spatial scale
# shrub = shrub cover at a relevant spatial scale
  
# These are continuous variables that are scaled to a mean of 0 and stdev of 1
  set.seed(51234) 
  x = data.frame(dist.dev=rnorm(n),forest=runif(n),shrub=runif(n)) 

# Create one dataset per each individual with equal
# Note that in the simulation function (simulateUsedAvail) we are specif icing 
# a link of 'log' indicating we will be fitting a model to estimate 
#  RELATIVE habitat selection rather than absolute selection.

  sims = apply(betas,1,FUN=function(b){
               ResourceSelection::simulateUsedAvail(data=x,
                                                    parms=b,
                                                    n.used=n.used,
                                                    m=m,
                                                    link="log"
                                                    ) 
    })

```
Before moving forward lets understand the data for one individual.
```{r data.examine}
# Check the dimensions of the data  
# This should have the same length as n.indiv  
  length(sims)

# Look at one individual's dataset
  dim(sims[[1]])
  head(sims[[1]])
  table(sims[[1]]$status)
```

We see from this individuals' data frame that we have the columns `r colnames((sims[[1]]))`. The column `status` is our response variable. A `1` indicates an animal location (used point) and a `0` indicates a potentially used location (i.e., available location) within the individual's home range. Each 1 and 0 have corresponding spatial variables, which we have called `dist.dev` (Euclidean distance to nearest development), `forest` (percent of landcover that is forested), and `shrub` (percent of landcover that is covered in shrub). Each of these is a continuous spatial variable and has been standardized to have a mean of 0 and standard deviation of 1 (also called Normalizing). This is a common setup in statistical models to put all the variables on an equivalent scale, i.e., the scale of one standard deviation. Note that we have a large available available sample, much more than the used sample. This is correct. Remember that the available sample (the 0's) is what is going to allow us to use logistic regression to approximate the IPP model.

We now want to package are simulated data into a single data frame. We will use the objects `sims` and `sims2` below when we want to fit models to each individual separately and together, respectively. 

```{r organize. simualted.data}
# Combine data into a single data.frame
  sims2 = do.call("rbind", sims)
  head(sims2)
  dim(sims2)

#Create ID vector for individual's data
  ID = rep(1:n.indiv, each = nrow(sims[[1]]))
  sims2$ID = ID
  head(sims2)
  dim(sims2)
  
# Create a vector to weight the 0's by 1000 and the 1's by 1
# This is discussed below  (see manuscript section 10. The model being approximated)
  sims2$weight = 1000^(1-sims2$status)
```

## Manuscript sections

We are now ready to fit models to estimate our habitat selection parameters and demonstrate points made in the manuscript. We have organized the sections below to generally match with the sections of the manuscript. 

### What is habitat?

Definitions only.

### What is habitat selection?

Definitions only.

### What is a habitat-selection function?

Definitions only. 

We want to remind the reader of the nuance between a habitat selection function and the statistical model we will be fitting. The model we are fitting (as coded) and the true underlying model (Inhomogeneous Poisson Point process; IPP) is not the habitat selection function. The habitat selection function is a component of the IPP model. We will be using a logistic regression modeling (or Generalized Binomial Regression Model) to approximate the IPP model, in which our estimated parameters will be the parameters within the habitat selection function. To understand the model, see equation 1 of [Gerber and Northrup, 2020](https://doi.org/10.1002/ecy.2953)

### What about scale?

Definitions only.

In our data setup and analysis we will be estimating habitat selection at the third-order of the scales defined in Johnson (1980). Most commonly, we can think of this as selection of habitat within a defined home-range. Our data generating process above was not specific about the spatial bounds of each individual's home-range, but this is how you can think of the data. The animal telemetry locations were used to create the 1's in our data and the corresponding spatial covariates (e.g., dist.dev) as well as the home range boundary. We then make a grid of points within the home range to extract the spatial covariate values and we assign these to the response of 0 and are the available sample. These two sets of values (1's and covariate values and 0's and covariate values) are appended together in a single data frame. 

There are many home-range estimators in the literature. Choose one that meets the requirements of your data, for example, whether there you have assume independence between consecutive spatial locations (e.g., kernel density estimation) or whether is spatial autocorrelation due to a high-frequency of sampling (e.g., short fix interval between relocations relative to the animals speed; movement-based kernel estimator).

### Why ‘habitat selection function’ and not ‘resource selection function’?

Definitions only.

### Considering objectives and data collection

This is the hardest part of the whole habitat selection study. How do you decide on the what, where, and how many individuals and relocations to answer the question at hand. Talk to many people. Ask questions to many people. 

The modeling mentioned here is about differences between study goals, such as inference and prediction. Modeling for inference versus prediction is not a straightforward distinction. There are lots of opinions from the statistical folks (which are great and everyone should read them, e.g., [Shmueli, 2010](https://doi.org/10.1214/10-STS330) and [Scholz and Burner, 2022](https://arxiv.org/abs/2210.06927)) and the science philosophy folks. 

We reference the manuscript [Gerber and Northrup, 2020](https://esajournals.onlinelibrary.wiley.com/doi/full/10.1002/ecy.2953) in regards to when the study goal is preditiction. Associated with this manuscript is code in the Supporting Information file (ecy2953-sup-0004-DataS1.Zip) that pertains to optimizing for predicting spatial distributions of habitat selection (i.e., making a map). This process can jeopardize inference, e.g., make the interpretation of estimated effects unreliable. In contrast, if inference is sought you should think hard about a single model that includes the most important variables for the species and for your question that you want to consider so that estimated effects and measures of uncertainty are reliable ([Bolker 2023](https://doi.org/10.32942/X2Z01P), [Tredennick et al. 2021](https://esajournals.onlinelibrary.wiley.com/doi/full/10.1002/ecy.3336)).

### What are habitat-selection functions used for?

In this section, we discuss some mechanics of inference and prediction, as in interpreting coefficients and predicting relative habitat selection. We will walk through the basics here, but refer the reader to full in depth coverage in [Fieberg et al. 2021](https://doi.org/10.1111/1365-2656.13441) and [Avgar et al. 2017](https://doi.org/10.1002/ece3.3122). We also mention the goal of using habitat selection to predict animal abundance. Demonstrating this is beyond our work. We suggest starting with the reading of section 1.6, "When is species density a reliable reflection of habitat suitability?" of [Matthiopoulos, Fieberg, and Aarts, 2023](http://hdl.handle.net/11299/217469).


#### Inference

Let's fit a model to one individual's used and available data and discuss the coefficients. 

```{r first.fit.inference}
# We will use data from individual #20
  indiv.data20 = sims[[20]]

# Let's look at the data to remind us what it is
  head(indiv.data20)
```

We are now ready to approximate our true model using the generalized linear modeling machinery of logistic regression. We will do this using two different packages and functions. First, we will use the `glmmTMB` function in package `glmmTMB`.

```{r first.fit.inference2}
# We have related our response variable of the used and available sample (status) to our covariates. This is an additive model, as opposed to having interactions.  
  model1 = glmmTMB::glmmTMB(status ~ dist.dev + forest + shrub, 
                            family = binomial(), 
                            data = indiv.data20 
                            )

# Look at estimated coefficients
  summary(model1)
```

Let's first consider the `Intercept`. As mentioned in the section '12. Population Inference', this parameter is largely the ratio of used to available sample. If we increase our available sample, this estimate will get smaller. Its value has a lot to do with how we setup the data to approximate the true underlying model. It has no biological interpretation, so we can skip it.

Next, we have estimated the effect of `dist.dev` as `r round(fixef(model1)[[1]][2],digits = 2)`. This estimate is negative, indicating that as the value of `dist.dev` increases from its mean (defined at 0) while the values of `forest` and `shrub` (the other variables in the model) are held at their mean that habitat selection decreases. In other words, habitat use relative to what is available to this individual (as we defined it!) decreases the further from development. That's a lot of qualifiers to understand this estimate. These are important though. In terms of evidence of an effect, we can say that at a defined Type I error of 0.05, we have a [statistically clear](https://doi.org/10.1111/2041-210X.13159) effect and that that it is not likely zero. The evidence of this is the very small p-value of `r summary(model1)[[6]][[1]][2,4]`. 

Next, we have estimated the effect of `forest` as `r round(fixef(model1)[[1]][3],digits = 2)`. This estimate is positive, indicating that as the value of `forest` increases from its mean (defined at 0) while the values of `dist.dev` and `shrub` (the other variables in the model) are held at their mean that habitat selection increases relative to what is available to this individual. At our defined Type I error we do not have statistical clarity and there is a reasonable chance that it is zero. (p-value =  `r summary(model1)[[6]][[1]][3,4]`). 

Next, we have estimated the effect of `shrub` as `r round(fixef(model1)[[1]][4],digits = 2)`. This estimate is positive, indicating that as the value of `shrub` increases from its mean (defined at 0) while the values of `dist.dev` and `forest` (the other variables in the model) are held at their mean that habitat selection increases relative to what is available to this individual. At our defined Type I error we do have statistical clarity of an effect that is not zero (p-value =  `r summary(model1)[[6]][[1]][4,4]`). 

##### **Other functions**

We can estimate the parameters with other functions that implement the logistic regression model. For example, the `glm` function in the `stats` package as:

```{r first.fit.inference.glm}
  model1.glm = stats::glm(status ~ dist.dev + forest + shrub, 
                          family = binomial(), 
                          data = indiv.data20 
                          )
  summary(model1.glm)
```

Notice that we estimate the exact same quantities. 

The package `amt` can do the same thing using the function `fit_rsf` which is a wrapper function for using the `stats glm` function.

```{r amt}
amt::fit_rsf
```

##### **Relative Selection**

How do we quantitatively evaluate two locations in terms of habitat selection using our model results? We can do so using Equation 8 of [Fieberg et al. 2021](https://doi.org/10.1111/1365-2656.13441).

Perhaps we want to compare a location that is very near development (dist.dev = -2) at high forest and shrub cover (forest = 2, shrub = 2) with that of a location far from development (dist.dev = 2) and also at high forest but low shrub cover (forest =2, shrub = -2).

```{r RS}
# Get estimates without the intercept
  coef = fixef(model1)[[1]][-1]

  RS = exp(-2*coef[1] + 2*coef[2] + 2*coef[3]) / 
       exp(2*coef[1] + 2*coef[2] + -2*coef[3])
  RS
```
If given equal availability, this individual would relatively select the first location by a factor of `r round(RS,digits=2)`. 

##### **Relative Selection Strength**
 
[Avgar et al. 2017](https://doi.org/10.1002/ece3.3122) refers to the relative selection strength (RSS) as the exponentiation of each coefficient. 

For example, 

```{r RSS}
# Coefficient for dist.dev
  exp(coef[2])
```

Given two locations that differ by 1 standard deviation of dist.dev, but are otherwise equal, this individual would be `r exp(coef[2])` as likely to choose the location with higher dist.dev  (or, equivalently, `r exp(-coef[2])` times more likely to choose the location with the lower dist.dev.

Why are we exponentiating our linear combinations of terms (additions of covariates times estimated coefficients)? This is because in this setup, we have assumed the habitat selection process follows an exponential form (see section 10. The model being approximated) and equation 1 of [Gerber and Northrup, 2020](https://doi.org/10.1002/ecy.2953).

#### Prediction

Lets combine our covariates now to predict relative habitat selection over more scenarios. To do this, we need to remember we used generalized linear modeling functions to approximate our model. We need to take care when predicting. First, we need to remember to drop the intercept. Second, we need to remember our true link function for relative habitat selection is the log-link (inverse-link is the exponential function) and not the logit-link, which is the default when fitting logistic regression models.

```{r predict}
# Force the intercept to be zero without any error
  model1$fit$par[1] = 0
  model1$sdr$par.fixed[1] = 0
  model1$sdr$cov.fixed[1,] = 0
  model1$sdr$cov.fixed[,1] = 0

# Create the dataframe for the combinations of variables for prediction  
  newdata=data.frame(dist.dev = seq(-2,2, by=0.1),
                     forest = 0,
                     shrub = 0
                     )
# Next, predict 
  preds = predict(model1,
                  type = "link",
                  newdata = newdata, 
                  se.fit = TRUE
                  )
# Use the Normal Approximation to get confidence intervals (other approachces are possible too!)  
  preds$LCL = preds$fit-1.96*preds$se.fit
  preds$UCL = preds$fit+1.96*preds$se.fit

  preds = data.frame(preds)  
  
# Exponentiate predicted values
  preds.exp = exp(preds[,-2])  
```

```{r predict.plot, class.source = "fold-hide"}
# Plot
  plot(newdata$dist.dev,preds.exp$fit,type="l",lwd=3,xlab="Distance to Development (Scaled)",
       ylab="Relative Intensity of Selection")
  lines(newdata$dist.dev,preds.exp$LCL,lwd=3,col=2,lty=4)
  lines(newdata$dist.dev,preds.exp$UCL,lwd=3,col=2,lty=4)
  abline(h=1, lwd=4, col=4)
  text(1.5,1.4, "Selection")
  text(1.5,0.6, "Avoidance")
```

We see that for this individual, given equal availability and `forest` and `shrub` at their mean values, avoid areas far from development (high values on x-axis) and select for areas close to development (low values on x-axis). 

We can use this same process to extract values across spatial layers to predict relative habitat selection that is mapped. 

### Traditional HSF or SSF?

In fitting these data using a traditional HSF, we are making two important assumptions. First, we are assuming that the available locations for an individual are accessible and could be used if the individual chooses. Note that in our data setup, we have not assumed the same set of available locations are the same for each individual. Each individual has a different set,  based on their home-range (remember this is not explicitly how we sampled, but it is implied). Second, we are assuming that each used location is independent from each other. Lets consider the implications of violating these assumptions.

#### Critical Assumption 1: Accessibility of habitat

We can demonstrate this effect by comparing results from individual 20 (above) with that of the same model but additional available locations are added to the available sample. Essentially, we are going to consider the effect of assuming these new locations are available to this individual. 

```{r assumption1}
# Create a new set of (small) available locations 
  n.avail.new = 50
  set.seed(215464)
  avail.new = data.frame(status = rep(0,n.avail.new),
                         dist.dev = rnorm(n.avail.new,-0.5,3),
                         forest = rnorm(n.avail.new,0.5,3),
                         shrub = rnorm(n.avail.new,1.5,3)
                        )

# Append the new data to the original data
  indiv.data20.appended = rbind(indiv.data20,avail.new)

# Fit the same model with appended data
  model1.appended = glmmTMB(status ~ dist.dev + forest + shrub, 
                            family = binomial(), 
                            data = indiv.data20.appended 
                            )
# Re-fit the original data
    model1 = glmmTMB::glmmTMB(status ~ dist.dev + forest + shrub, 
                              family = binomial(), 
                              data = indiv.data20 
                            )
  
# Compare coefficients using the appended data and the original data
  coef.df = rbind(fixef(model1)[[1]][-1],
                  fixef(model1.appended)[[1]][-1]
                  )
  colnames(coef.df) = c("dist.dev","forest","shrub")
  rownames(coef.df) = c("Original Data","Data with Inaccessible")
  knitr::kable(coef.df)  
```

**What did we find?** Simply, that our estimates are quite different when considering these additional available locations that were inaccessible to the individual. That is a challenge for us when setting up the data. Our estimates can change quite a bit. This is an important reminder that our estimated effects highly depend on our assumptions of what is available to each animal. We want to avoid including available locations that are in fact inaccessible to the animal because it will change our inference in unknown ways.

#### Critical Assumption 2: Independence of location data

We can evaluate this assumption by including non-independent data. We can easily do this by replicating our used animal location data. It's as if we were tracking an individual and took two locations every 4 hours, where the 2 location fixes were only separated by 5 minutes. While 4 hours may be enough for the individual to travel throughout its home range (if it chooses), 2 minutes is certainly not enough time. Thus, we have two data points really close in space and time for every 4 hour interval.

```{r assumption2}

# Lets use indidual 7's data
  indiv.data7 = sims[[7]]

# Find the used locations
  index1 = which(indiv.data7$status==1)

# Replicate the used locations 
  indiv.data7.replicated = rbind(indiv.data7,
                                 indiv.data7[index1,]
                                )

  fit.replicated = glmmTMB(status ~ dist.dev + forest + shrub  , 
                           family = binomial(), 
                           data = indiv.data7.replicated, 
                           )

# Fit the original data
    model1 = glmmTMB::glmmTMB(status ~ dist.dev+forest+shrub, 
                              family = binomial(), 
                              data = indiv.data7 
                            )
  
# Compare coefficients when using the replicated data and the original data
  coef.df[1,] = fixef(model1)[[1]][-1]
  coef.df[2,] = fixef(fit.replicated)[[1]][-1]
  rownames(coef.df)[2] = "Non-Independent Data"
  knitr::kable(coef.df)
```

**What did we find?** Well, the point estimates look similar. That's good. Now let's look at measures of uncertainty.

```{r assumption2.2}

# Compare measures of uncertainty
  summary(model1)
  summary(fit.replicated)
```

Okay, so this is not so good. We can see the standard errors of the estimates from the model `fit.replicated` are  smaller because we inappropriately doubled our sample size and treated dependent data as indepednent. This effect will translate into much too small confidence intervals for our estimates and predictions. It also means that our p-values are too small. Notice that our coefficient for forest is now statistically clearly different than zero (p-value of `r summary(fit.replicated)[[6]][[1]][3,4]`) while it was not so using only independent data (p-value of `r summary(model1)[[6]][[1]][3,4]`).


### The model being fit

Context only.

### The model being approximated

It is the responsibility of each researcher to make sure their modeling process is done such that they are approximating the true underlying Inhomogeneous Poisson Point process (IPP) model well. To demonstrate this, we will consider how estimated coefficients change with increasing numbers of available samples. We will also be able to see how the intercept changes, due its partial (mostly) interpretation as a measure of the ratio of used to available samples. 

In practice, there are two components that need to be considered in the approximation. First, is how to sample the complexity of variation in the spatial covariates being considered. Simply, you want to make sure that the spatial variation is captured with these discrete locations by spreading them out well. Second, is to have enough of these samples such that the approximation works well. Capturing the spatial variation is best done by making a systematic grid of locations within the area that is considered available and extracting the covariate values. Having enough available locations can be achieved by having a high density of points for the systematic grid and also by weighting the available locations within the model fitting process. 

Since we are not explicitly spatially sampling here, we can't directly evaluate how to capture spatial variation, but we can demonstrate how to weight the available locations. Essentially, you want to tell the model that for every used location to weight this data by 1, indicating that there is one of them. For the available locations, you want to weight each location by a large number (e.g.,1000). This tells the model to consider this data as having 1000 of them. You can think of it as a shortcut to replicating this available location and its covariate values 1000 times. Either way works, but weighting is more computationally efficient. Note that this type of replicating of the available sample is a good thing, while replicating the used data (as seen in Critical Assumption 2: Independence of location data) is not a good thing.

```{r sensitiivity, cache=TRUE}

# Grab individual one's data
  indiv.dat1 = sims[[1]]

# index the used (1) and available (0) data
  index.0 = which(indiv.dat1==0)
  index.1 = which(indiv.dat1==1)

# Create a sequence of the number of available locations to consider
  n.available = seq(10,length(index.0),by=100)

# Create storage objects  
  coef.save = NULL

# Loop through and modify the data and fit each model with increasing 
# number of available samples
  for(i in 1:length(n.available)){
    dat.temp = rbind(indiv.dat1[index.1,],
                     indiv.dat1[index.0[1:n.available[i]],]
                     )
  
  #Create the weighting vector (a 1 for each 1 and a 1000 for each 0)
  dat.temp$weight = 1000^(1-dat.temp$status)
  
  model.fit =  glmmTMB(status ~ dist.dev + forest + shrub, 
                        family = binomial(), 
                        data =  dat.temp,
                        weight = weight # add the weighting vector
                        )
  

  coef.save = rbind(coef.save,
                    fixef(model.fit)[[1]]
                  )
}

coef.save = data.frame(n.available,coef.save)
colnames(coef.save) = c("N.Avail","Intercept","beta1","beta2","beta3")
```

```{r plotting.sensitivity, , fig.height=8, fig.width=6, class.source = "fold-hide"}
par(mfrow=c(2,1))
plot(coef.save$N.Avail, coef.save$beta1,lwd=3,type="l",col=2,ylim=c(-1.5,1.5),
     main="Slope Coeficients",
     xlab="Number of Available Samples",ylab="Coeficient Estimate")
lines(coef.save$N.Avail, coef.save$beta2,lwd=3,col=2)
lines(coef.save$N.Avail, coef.save$beta3,lwd=3,col=2)
plot(coef.save$N.Avail, coef.save$Intercept,lwd=3,type="l",col=1,main="Intercept",
     xlab="Number of Available Samples",ylab="Coeficient Estimate")
```

We can see that our estimates of the slope coefficients are sensitive to the number of available locations when there are less than a few thousand available locations; there is still a bit of jumping around until the available samples are above 4000. In contrast, we can see the intercept just keep getting smaller and smaller because our available sample size is getting larger and larger. The intercept is not biologically meaningful. 


Another way to look at this sensitivity is by showing the variability of the coefficients within and across different sizes of available samples.

```{r sensitiivity2, cache=TRUE,warnings=FALSE}
# Size of available samples per used locaiton
  n.avail2 = c(10,50,100,1000,2000,4000)
  
# Number of sample replications
 n.sample = 20

#Save coefficients
  coef.save=NULL
  
#Loop across available sample sizes  
  for(i in 1:length(n.avail2)){
  
  #re-sample each available sample size 20 times  
  for (z in 1:n.sample){
  #Loop through each used location and reduce the number of available samples and do this n.sample times
    ind.dat = NULL

    dat.temp = rbind(indiv.dat1[index.1,],
                     indiv.dat1[sample(index.0,n.avail2[i]),]
                     )
    
  #Create the weighting vector (a 1 for each 1 and a 1000 for each 0)
  dat.temp$weight = 1000^(1-dat.temp$status)
  
  model.fit =  glmmTMB(status ~ dist.dev + forest + shrub, 
                        family = binomial(), 
                        data =  dat.temp,
                        weight = weight # add the weighting vector
                        )
  
  coef.save= rbind(coef.save, 
                   model.fit$fit$par
                   )
  }#end z sample loop
}#end i loop
  
```

```{r plot.sensitive.org2, class.source = "fold-hide"}
one = data.frame(N.Avail = rep(n.avail2,each = n.sample),
                 Sample = rep(1:n.sample,length(n.avail2)),
                 beta = coef.save[,1]
                )
two = data.frame(N.Avail = rep(n.avail2,each = n.sample),
                 Sample = rep(1:n.sample,length(n.avail2)),
                 beta = coef.save[,2]
                )
three = data.frame(N.Avail = rep(n.avail2,each = n.sample),
                 Sample = rep(1:n.sample,length(n.avail2)),
                 beta = coef.save[,3]
                )
four = data.frame(N.Avail = rep(n.avail2,each = n.sample),
                 Sample = rep(1:n.sample,length(n.avail2)),
                 beta = coef.save[,4]
                )

plot.data = rbind(one,two,three,four)
plot.data$Name = c(rep("Intercept",nrow(one)),
                   rep("dist.dev",nrow(one)),
                   rep("forest",nrow(one)),
                   rep("shrub",nrow(one))
                 )

plot.data$N.Avail = as.factor(plot.data$N.Avail)


colnames(plot.data) = c("N.Available.Sample","Sample","Coeficient.Estiamte","Name")

ggplot2::ggplot(plot.data, aes(N.Available.Sample, Coeficient.Estiamte, fill=factor(Name))) +
  theme_bw()+
  geom_boxplot()
```

We see more easily in this plot that there is high variability in the estimated coefficients  when the available sample is small. This variability decreases as the available sample grows, showing how the estimates are stabilizing (except the intercept). What this means is that you could grab many different but large available samples and would get almost the same estimated coefficients. This is not true when using a small available sample; your estimated coefficients will vary and we do not want. The intercept estimates decrease in the variability but also continues to decline. 

### Individuals 

We should a priori assume there is individual variation in habitat selection estimates. This variation is masked when data are pooled. Lets consider the implications of pooling all data vs fitting a model separately to each individual.

```{r pooling,cache=TRUE}
# Pooled model - no consideration of individual variability
  model.pool = glmmTMB(status ~ dist.dev + forest + shrub , 
                       family = binomial(), 
                       data = sims2, 
                    )

# Separate models to each individual
  indiv.fit = lapply(sims, FUN = function(x){
                     glmmTMB(status ~ dist.dev + forest + shrub ,
                             family = binomial(), 
                             data = x, 
                            )
                      })
  
# Look at estimates when pooling the data
  summary(model.pool)
```

In the pooled data, we see that the standard errors of the coefficients and p-values are very small. We are using a lot of information, assuming no variation among individuals, and thus assuming every individual's effects can be characterized by these estimates. We are also forcing the intercept to be the same for each individual. That's fine here because we have the same number of used locations for each individual and thus the ratio of used to available is the same. But, if you have differing number of used sampled per individual, this would not be a good thing. Now let's, look at just two individual's estimates when fitting separate models.

```{r separate}
summary(indiv.fit[[2]])
```

First, notice that the estimated effects are a bit different than the pooled estimates. Importantly, also notice that the standard errors and p-values are larger.

```{r separate2}
summary(indiv.fit[[20]])
```

Now lets look at all the estimates together.

```{r estimate.pool.separate}
# Extract pooled estimates with Confidence intervals
pool.effect = broom.mixed::tidy(model.pool, effects = "fixed", conf.int = TRUE)

# Extract separate individual estimates
indiv.coef = lapply(indiv.fit,FUN=function(x){
                      temp=broom.mixed::tidy(x, effects = "fixed", 
                                             conf.int = TRUE
                                             )
                      data.frame(temp[-1,c(4,8,9)])
})

# These are all coefs (1:3) for each individual 1:n.indiv
  estimates = sapply(indiv.coef,"[[",1)
  LCI = sapply(indiv.coef,"[[",2)
  UCI = sapply(indiv.coef,"[[",3)
```

```{r plot.pool.separate, class.source = "fold-hide"}
layout(matrix(c(1,2), nrow = 1, ncol = 2, byrow = TRUE),
       width=c(2,1)
       )
plotCI(1:n.indiv,y=estimates[1,],
       ui=UCI[1,],
       li=LCI[1,],
       ylab="beta",
       xlab="Individual",
       lwd=2,
       ylim=c(-2.5,4)
)
 legend("topright",lwd=3,col=c(1,2,3),legend=c("dist.dev","forest","shrub"),box.lty=0,
        y.intersp=0.8)
 
plotCI(1:n.indiv,y=estimates[2,],
       ui=UCI[2,],
       li=LCI[2,],
       ylab="beta_1",
       xlab="Individual",
       lwd=2,
       col=2,
       add=TRUE
       )
plotCI(1:n.indiv,y=estimates[3,],
       ui=UCI[3,],
       li=LCI[3,],
       ylab="beta_1",
       xlab="Individual",
       lwd=2,
       col=3,
       add=TRUE
       )
plotCI(c(1,1,1),y=pool.effect$estimate[2:4],
       xlim=c(0.95,1.05),
       ui=pool.effect$conf.high[2:4],
       li=pool.effect$conf.low[2:4],
       ylab="beta",
       xlab="Population",
       lwd=2,
       ylim=c(-2.5,4),
       col=c(1,2,3),
       xaxt='n'
       )
```

The plot on the right are the pooled estimates for beta1 (black), beta2 (red), and beta3 (green). The plot on the left are each individual's estimates (colored the same). By ignoring individual variation, we are a much too confident in our estimates of uncertainty and are ignoring a lot of clear variation by individual. The pooled estimates certainty has to do with psuedoreplication - the treating a subunit (each location) as the main unit of replication. Our true unit of replication is the individual. 

Since our sample sizes for each individual are equal, we see that the pooled estimates generally relate to the average of each estimate across all individuals. When the number of used locations varies by individual this won't be the case. The individual's with more used locations will disproportionately influence the pooled estimates. 

#### Sample size

The code for implementing the methods of [Street et al. 2021](https://doi.org/10.1111/2041-210X.13701) can be found at [figshare](https://figshare.com/articles/dataset/Datasets_and_Code_zip/11910831). We are working on a more user friendly implementation.


### Population inference

If we are interested in obtaining inference to the individual- and population-level effects, we can consider bootstrapping the results from individual models or jointly fitting a single model with a random effect across individuals. We will first consider the bootstrapping method. Second, we will demonstrate the use of random intercepts and slopes, as well as how to fix the variance of the random intercept so there is no shrinkage. 

#### Bootrapping

The core functions for bootstrapping are adopted from Dr. Bastille-Rousseau's github repository for the R package [IndRSA](https://github.com/BastilleRousseau/IndRSA/).

We first need to get all estimated coefficients from each individual. 

```{r boot.setup}
  coef.list = lapply(indiv.fit,FUN=function(x){fixef(x)[[1]]})
  
  coef.df=do.call(rbind.data.frame, coef.list)
  colnames(coef.df)=names(fixef(indiv.fit[[1]])[[1]])

# Remove intercept
  coef.df = coef.df[,-1]

# Add name (could be modified to keep track if animals have an ID)
  coef.df$name = 1:nrow(coef.df)

# Frequency could be greater than one if there were multiple estimates of a single individual, perhaps across years
  coef.df$freq = 1
```

We are ready to bootstrap the coefficient estimates.

```{r boot}
#How many bootstraps to do? More will lead to results with less error
  nboot = 1000

#Which columns have coeficients in coef.df
  col.locs=1:3

  boot=list()
  for(i in 1:nboot){
    boot[[i]]=apply(
                     coef.df[sample(nrow(coef.df), nrow(coef.df), 
                                    replace=TRUE, 
                                    prob=coef.df$freq),
                             col.locs 
                             ],
                     2, 
                     median, 
                     na.rm=TRUE
                     ) 
  }
```

We now want to summarize our bootstrapped results. The population mean and 95% lower and upper confidence intervals are outputted.  

```{r boot.summary}
  boot.pop.esimates=mean_ci_boot(boot)
  knitr::kable(boot.pop.esimates)
```

#### Random effects across individuals

##### Random intercept only model

The most common use of random effects in habitat selection analysis is the use of a random intercept. As described in the manuscript, this does not account for variation in the slope coefficients, which is problematic. 

```{r random.intercept, cache=TRUE}
# Setup HSF with logistic regression approximation - random intercept model
# Do not fit the model
   re_int = glmmTMB(status ~ dist.dev + forest + shrub  + (1|ID), 
                    family = binomial(), 
                    data = sims2, 
                    doFit = FALSE
                    )

# Make the intercept large and fixed
  re_int$parameters$theta[1] = log(1e3)
  
# Tell glmmTMB to not estimate the intercept  
  re_int$mapArg = list(theta=factor(c(NA)))
  
# Now ready to fit the model  
  re_int = glmmTMB:::fitTMB(re_int)
```

```{r examine random intercept model}
# The fixed components - these are the population level (across individual) effects. 
  fixef(re_int)
  
# The random components- these are the effect differences for each individual from the population mean estimate (referred to as the fixed effect in the 'conditional model' statement)
  ranef(re_int)
  
# Summarize results  
  summary(re_int)
```

A random intercepts only model is not recommended. 


#### Random intercept and slopes model

This is the recommended model structure using random effects. 

```{r model2, cache=TRUE}
  
#Fit RSF with intercept and slopes with random effect
  re_int_slopes =  glmmTMB(status ~ dist.dev + forest + shrub  + 
                                     (1|ID) + (0+dist.dev|ID) +
                                     (0+forest|ID) + (0+shrub|ID), 
                            family = binomial(), 
                            data = sims2, 
                            doFit = FALSE, 
                            weights = weight
                            )
# make the intercept large and fixed
  re_int_slopes$parameters$theta[1] = log(1e3)
  
# Tell glmmTMB to not estimate the intercept, but 
# to do so for the other three variables
  re_int_slopes$mapArg = list(theta=factor(c(NA,1:3)))
  
# Now ready to fit the model    
  re_int_slopes = glmmTMB:::fitTMB(re_int_slopes)
```

Let's look at the results

```{r RE.results.fixed}
  fixef(re_int_slopes)
  broom.mixed::tidy(re_int_slopes, effects = "fixed", conf.int = TRUE)[-1,c(3,4,8,9)]
```

Here are estimated population-level coefficients (across individual-level effects). Compared to the bootstrapped results above, they are generally similar. We should not expect them to be the same, as the random effect model shares information across individuals and the bootstrapped estimates do not. 


We can also extract the estimated difference by individual from the population level coeficients. 

```{r RE.results.random}
  ranef(re_int_slopes)
  broom.mixed::tidy(re_int_slopes, effects = "ran_vals", conf.int = TRUE)[-c(1:20),c(5,6,8,9)]

```

Lastly, we can see a full summary of the model.

```{r RE.results}
summary(re_int_slopes)
```
Note the variance and standard deviation estimates, indicating how variable coefficients are across individuals. We see that `forest` is estimated as the most variable. This corresponds well to how the data were generated with forest coefficients having the highest standard deviation of `r beta2.sd``.

Another thing to notice is that the population level effect for forest is not statistically clearly different than zero. Thus, at the population level, percent forest is being selected in proportion to what is available to each individual. Let's dive into this a bit more. Let's plot the individual estimated along with the population-level estimate.

```{r RE.est.forest.indiv.pop}

  indiv.coef.popModel = broom.mixed::tidy(re_int_slopes, 
                                          effects = "ran_vals", 
                                          conf.int = TRUE)
  indiv.forest.popModel = data.frame(indiv.coef.popModel[41:60,c(5,6,8,9)])

# Add back mean to get individual estimates  
  indiv.forest.popModel[,2:4] = indiv.forest.popModel[,2:4]+
                                rep(fixef(re_int_slopes)[[1]][3],each=20)
    
# Extract population mean and uncertainty for forest effect
  pop.coef.popModel = data.frame(broom.mixed::tidy(re_int_slopes, 
                                                   effects = "fixed",
                                                   conf.int = TRUE)
                                 )
  pop.coef.popModel=pop.coef.popModel[3,c(4,8,9)]
```

```{r RE.plot.forest.indiv.pop, class.source = "fold-hide"}
#Plot
  plotCI(x = 1:20,
         y = indiv.forest.popModel$estimate,
         ui = indiv.forest.popModel$conf.high,
         li = indiv.forest.popModel$conf.low,
         lwd = 3,col=1,
         xlab="Individual",ylab="Forest Coeficient")
  abline(h=pop.coef.popModel$estimate,lwd=3,col=1,lty=4)
  abline(h=pop.coef.popModel$conf.low,lwd=3,col=2,lty=4)
  abline(h=pop.coef.popModel$conf.high,lwd=3,col=2,lty=4)
```

Our plot shows the individual effects of `forest` along with the population-level. What is clear is that the reason there is no statistically clear difference of the population-level effect from zero is because there is a wide range of effects across individuals. Some individuals have positive coefficients and some have negative. Since these are generally equal, they balance out to a population-level effect of zero. The story is more complicated!

### Considering context in habitat selection analyses

In this section we discuss ways of considering behavior in habitat selection analyses. To demonstrate the effect of ignoring behavior, we will simulate data where selection is different for two sets of animal locations. Imagine an animalis highly selective of being in the landcover of forest when it is resting, but when foraging (and otherwise) selects against landcover in proportion to its availability. 

```{r behav.sim, class.source = "fold-hide"}

# Setup simulation input where there is more data from the second behavior
 n.used.behav1 = 200
 n.used.behav2 = 200

# Ratio of used:available
  m = 10 
  
#Create available samples  
  n1 = n.used.behav1*m
  n2 = n.used.behav2*m 

# Consider a single categorical variable of forest and not-forest
  set.seed(51234) 
  x1 = data.frame(forest = rbinom(n1,1,0.4))
  x2 = data.frame(forest = rbinom(n2,1,0.4)) 

# Intercept and effect of forest
  parms.behav1 = c(0.5,2) # the 2 indicates selection
  parms.behav2 = c(0.5,-2) # the -0 indicates avoidance
  
# simulate data  
  sim.behav1 = ResourceSelection::simulateUsedAvail(data = x1,
                                                   parms = parms.behav1,
                                                   n.used = n.used.behav1,
                                                   m = m,
                                                   link = "log"
                                                   ) 
  sim.behav2 = ResourceSelection::simulateUsedAvail(data = x2,
                                                   parms = parms.behav2,
                                                   n.used = n.used.behav2,
                                                   m = m,
                                                   link = "log"
                                                   ) 
# Combine the data  
  data.ignore = rbind(sim.behav1,
                      sim.behav2
                      )  
```

Lets fit a model where we ignore the behavioral differences in selection and fit a single model with all the data. 

```{r behav.fit}
  model.ignore.behav = glmmTMB::glmmTMB(status ~ forest, 
                                        family = binomial(), 
                                        data = data.ignore 
                                        )
  summary(model.ignore.behav)
```

We see that the estimated forest coefficient is not near the true values of -2 or 2. It's somewhat in between near zero. Essentially, when animals are selecting different habitat features because of behavior, mixing across behaviors can lead to a muddled inference. 


### Interpreting coefficients and predicting

Interpreting coefficients and predicting is outlined above in subsection `7. What are habitat-selection functions used for?`.

### Model selection

If focused on inference, fitting a single model is not only okay, but desirable. 

### Concluding remarks

We hope this vignette proided some utility. If so, let us know with an email (brian.gerber@colostate.edu). 

Have a nice day.

## Software

This report was generated from the R Statistical Software (v4.4.2; R Core Team 2021) using the [Markdown language](https://www.markdownguide.org/) and [RStudio](https://posit.co/products/open-source/rstudio/). The R packages used are acknowledged below. 

```{r packages.cite, eval=TRUE, echo=FALSE}
  pkgs = cite_packages(output = "table", out.dir = ".",out.format ="pdf")
  knitr::kable(pkgs)
```
